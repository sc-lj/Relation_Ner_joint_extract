{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('py36': conda)",
   "metadata": {
    "interpreter": {
     "hash": "0071b0df4086e0dd43ff94b5e10b228431ac274c4976b692451948239530b261"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "300\n171293\n246\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import json\n",
    "from collections import Counter\n",
    "files = \"./data/baidu/duie_train.json\"\n",
    "with open(files,\"rb\") as f:\n",
    "    data = f.readlines()\n",
    "index = 0\n",
    "a = ['上映时间', '专业代码', '改编自', '修业年限', '成立日期', 'ondate_date', '董事长', '注册资本', '占地面积', '人口数量', '所属专辑', 'inwork_影视作品', '编剧', '歌手', '票房', '导演', '主演', 'period_number', '邮政编码', '作者', '简称', '面积', '作曲', '作词']\n",
    "predicates = set()\n",
    "max_leng = 0\n",
    "len_ = []\n",
    "for line in data:\n",
    "    line = json.loads(line)\n",
    "    spo_list = line['spo_list']\n",
    "    text = line['text']\n",
    "    max_leng = max(len(text),max_leng)\n",
    "    len_.append(len(text))\n",
    "    for spo in spo_list:\n",
    "        s = spo['subject']\n",
    "        p = spo['object']['@value']\n",
    "        predicate = spo['predicate']\n",
    "        if ( s.isdigit() or p.isdigit() ) and predicate == a[1]:\n",
    "            # print(p+\"\\t\"+predicate+\"\\t\"+s+\"\\t\"+text)\n",
    "            predicates.add(predicate)\n",
    "            index += 1\n",
    "# print(predicates)\n",
    "print(max_leng)\n",
    "print(len(len_))\n",
    "print(sum([1 if l>250 else 0 for l in len_]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "aa = np.array([[0.0349,  0.0670, -0.0612, 0.0280, -0.0222,  0.0422],\n",
    "         [-1.6719,  0.1242, -0.6488, 0.3313, -1.3965, -0.0682],\n",
    "         [-1.3419,  0.4485, -0.6589, 0.1420, -0.3260, -0.4795]])\n",
    "bb = np.array([[-0.0658, -0.1490, -0.1684, 0.7188,  0.3129, -0.1116],\n",
    "         [-0.2098, -0.2980,  0.1126, 0.9666, -0.0178,  0.1222],\n",
    "         [ 0.1179, -0.4622, -0.2112, 1.1151,  0.1846,  0.4283]])\n",
    "cc = np.where(aa>0)     #合并a,b两个tensor，如果a中元素大于0\n",
    "dd = np.where(bb>0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "sub_heads = torch.tensor([2,3,2,5,2,7,6,7,8,2])\n",
    "sub_tails = torch.tensor([5,7,5,2,7,3,8,7,8,7])\n",
    "sub_head_mapping = torch.zeros(10,1,9)\n",
    "sub_tail_mapping = torch.zeros(10,1,9)\n",
    "sub_head_mapping.scatter_(-1,sub_heads.reshape(10,1,1),1)\n",
    "sub_tail_mapping.scatter_(-1,sub_tails.reshape(10,1,1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "text = \"内地影视演员龚蓓苾携手周渝民、迪丽热巴、张彬彬、刘芮麟、赖艺、代斯、张赫等主创悉数出席\"\n",
    "tokenizer = BertTokenizer.from_pretrained(\"../chinese_bert_base\")\n",
    "# print(tokenizer.tokenize(text))\n",
    "# token = ['龚', '蓓', '苾', '携', '手', '周', '渝', '民', '、', '迪', '丽', '热', '巴', '、', '张', '彬', '彬', '、', '刘', '芮', '麟', '、', '赖', '艺', '、', '代', '斯', '、', '张', '赫', '等', '主', '创', '悉', '数', '出', '席']\n",
    "# tokenizer.convert_tokens_to_ids(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([10, 30, 100])\ntorch.Size([10, 30, 4, 100])\ntorch.Size([10, 30, 4, 50])\ntorch.Size([10, 30, 4, 25])\ntorch.Size([10, 30, 4, 25, 2])\ntorch.Size([10, 30, 4, 50])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "head_size = 50\n",
    "heads=4\n",
    "a = torch.rand(10,30,head_size* heads * 2)\n",
    "input1 = torch.split(a,head_size*2,dim = -1)\n",
    "print(input1[0].shape)\n",
    "input2 = torch.stack(input1, axis=-2)\n",
    "print(input2.shape)\n",
    "qw, kw = input2[..., :head_size], input2[..., head_size:]\n",
    "print(qw.shape)\n",
    "print(qw[..., 1::2].shape)\n",
    "qw2 = torch.stack([-qw[..., 1::2], qw[..., ::2]], 4)\n",
    "print(qw2.shape)\n",
    "qw2 = torch.reshape(qw2, qw.shape)\n",
    "print(qw2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10, 20, 400)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "inputs = tf.random_normal((10,20,head_size* heads * 2))\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n(10, 20, 100)\n(10, 20, 4, 100)\n(10, 20, 4, 50)\n(10, 20, 4, 25, 2)\n(10, 20, 4, 50)\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.split(inputs, heads, axis=-1)\n",
    "print(len(input1))\n",
    "print(input1[0].shape)\n",
    "input2 = K.stack(input1, axis=-2)\n",
    "print(input2.shape)\n",
    "qw, kw = input2[..., :head_size], input2[..., head_size:]\n",
    "print(qw.shape)\n",
    "qw2 = K.stack([-qw[..., 1::2], qw[..., ::2]], 4)\n",
    "print(qw2.shape)\n",
    "qw2 = K.reshape(qw2, K.shape(qw))\n",
    "print(qw2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 100, 25, 2])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.rand((10,100,20))\n",
    "output_dim = 50\n",
    "position_ids = torch.arange(0, 100, dtype=torch.float).reshape(1,-1)\n",
    "indices = torch.arange(0, output_dim // 2, dtype=torch.float)\n",
    "indices = torch.pow(10000.0, -2 * indices / output_dim).reshape(1,-1)\n",
    "embeddings = torch.matmul(position_ids.unsqueeze(-1),indices.unsqueeze(0))\n",
    "embeddings = torch.stack([torch.sin(embeddings), torch.cos(embeddings)], axis=-1)\n",
    "# embeddings = torch.reshape(embeddings, (-1, 100, output_dim))\n",
    "print(embeddings.shape)\n",
    "# embeddings = embeddings.repeat([10, 1, 1])\n",
    "# torch.cat([inputs, embeddings],axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(25,)\n(1, 100, 50)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat:0' shape=(10, 100, 70) dtype=float32>"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "inputs = tf.random_normal((10,100,20))\n",
    "position_ids = K.arange(0, 100, dtype=K.floatx())[None]\n",
    "\n",
    "indices = K.arange(0, output_dim // 2, dtype=K.floatx())\n",
    "indices = K.pow(10000.0, -2 * indices / output_dim)\n",
    "print(indices.shape)\n",
    "embeddings = tf.einsum('bn,d->bnd', position_ids, indices)\n",
    "embeddings = K.stack([K.sin(embeddings), K.cos(embeddings)], axis=-1)\n",
    "embeddings = K.reshape(embeddings, (-1, 100, output_dim))\n",
    "\n",
    "print(embeddings.shape)\n",
    "embeddings = K.tile(embeddings, [10, 1, 1])\n",
    "K.concatenate([inputs, embeddings])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([10, 2, 30, 20])\ntorch.Size([10, 2, 30, 20])\ntorch.Size([10, 2, 20, 30])\ntorch.Size([10, 2, 20, 30])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "qw = torch.rand(10,30,2,20)\n",
    "kw = torch.rand(10,30,2,20)\n",
    "# torch.matmul(qw.transpose(2,1),kw.permute(0,3,1,2))\n",
    "print(qw.transpose(2,1).shape)\n",
    "kww = kw.transpose(2,1)\n",
    "print(kww.shape)\n",
    "print(kww.transpose(3,2).shape)\n",
    "print(kw.permute(0,2,3,1).shape)\n",
    "kww.transpose(3,2) == kw.permute(0,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.1007533\n[0.6931472 1.6931472 2.6931472]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[0., 1., 2.], [0., 1., 2.]])\n",
    "y1 = tf.reduce_logsumexp(x)             # 3.1007533\n",
    "y2 = tf.reduce_logsumexp(x, 0)\n",
    "\n",
    "sess = tf.Session()\n",
    "# Evaluate the tensor `c`.\n",
    "\n",
    "print(sess.run(y1))\n",
    "print(sess.run(y2))\n",
    "x = torch.tensor([[0., 1., 2.], [0., 1., 2.]])\n",
    "y2 = torch.logsumexp(x, dim=0)\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor(0.9429)\ntensor(0.5409)\ntensor(0.8270)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "a= torch.zeros((3,20))\n",
    "b= torch.zeros((3,20))\n",
    "a[0,5] = 1\n",
    "a[1,7] = 1\n",
    "a[2,2] = 1\n",
    "b[0,10] = 1\n",
    "b[1,16]=1\n",
    "b[2,14]=1\n",
    "c = torch.rand(3,20,20)\n",
    "print(c[0,5,10])\n",
    "print(c[1,7,16])\n",
    "print(c[2,2,14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 0,  5, 10],\n",
       "        [ 1,  7, 16],\n",
       "        [ 2,  2, 14]])"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "def th_gather_nd(x, coords):\n",
    "    x = x.contiguous()\n",
    "\n",
    "    inds = coords.mv(torch.LongTensor(x.stride()))\n",
    "    x_gather = torch.index_select(x.contiguous().view(-1), 0, inds)\n",
    "    return x_gather\n",
    "head = torch.nonzero(a)[:,1]\n",
    "tail = torch.nonzero(b)[:,1]\n",
    "head_tail = torch.vstack((head,tail)).T\n",
    "batch = c.shape[0]\n",
    "index = torch.hstack([torch.arange(batch).reshape(-1,1),head_tail])\n",
    "# torch.index_select(c,[1,2],head_tail)\n",
    "# th_gather_nd(c,index)\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([0.9429, 0.5409, 0.8270])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "idx_chunked = head_tail.chunk(2,1)\n",
    "masked = c[torch.arange(3).view(3,1),idx_chunked[0].squeeze(),idx_chunked[1].squeeze()]\n",
    "# masked.expand(1,*masked.shape)\n",
    "diag = torch.diag(masked)\n",
    "diag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[5],\n",
       "         [7]]),\n",
       " tensor([[10],\n",
       "         [16]]))"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "idx_chunked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([[[1],\n",
       "          [0],\n",
       "          [1],\n",
       "          [0]],\n",
       " \n",
       "         [[1],\n",
       "          [1],\n",
       "          [1],\n",
       "          [1]]]),\n",
       " tensor([[[0],\n",
       "          [0],\n",
       "          [1],\n",
       "          [0]],\n",
       " \n",
       "         [[0],\n",
       "          [1],\n",
       "          [1],\n",
       "          [0]]]))"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "torch.randint(0,2,(2,4,2)).chunk(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = index[:,0]\n",
    "start = index[:,1]\n",
    "end = index[:,2]\n",
    "d= a+b\n",
    "seq_len = d.shape[-1]\n",
    "seqs = torch.zeros_like(d)\n",
    "seqs[:,:]= torch.arange(seq_len)\n",
    "# d[:,:start] = 1\n",
    "start_index = (seqs<start.reshape(-1,1)).int()\n",
    "end_index = (seqs<=end.reshape(-1,1)).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "new_index = start_index+end_index\n",
    "new_range = (new_index==1).int()\n",
    "new_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "    def get_range_head_tail(head,tail):\n",
    "        head_index = torch.nonzero(head)[:,1]\n",
    "        tail_index = torch.nonzero(tail)[:,1]\n",
    "        mask = torch.zeros_like(head)\n",
    "        seq_len = head.shape[-1]\n",
    "        mask[:,:]= torch.arange(seq_len)\n",
    "        start_range = (mask<head_index.reshape(-1,1)).int()\n",
    "        end_range = (mask<=tail_index.reshape(-1,1)).int()\n",
    "        new_mask = start_range+end_range\n",
    "        new_mask = (new_mask==1).int()\n",
    "        return new_mask\n",
    "get_range_head_tail(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"text\": \"1CN5A科技广场为2010年在淘宝成立的一家及数码产品,网络设备,音响设备,电脑周边产品，虚拟产品等于一体的综合性网络商店.\", \"spo_list\": [{\"predicate\": \"成立日期\", \"object_type\": {\"@value\": \"Date\"}, \"subject_type\": \"机构\", \"object\": {\"@value\": \"2010年\"}, \"subject\": \"CN5A科技广场\"}, {\"predicate\": \"成立日期\", \"object_type\": {\"@value\": \"Date\"}, \"subject_type\": \"机构\", \"object\": {\"@value\": \"2010年\"}, \"subject\": \"1CN5A科技广场\"}]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "\"CN5A科技广场\" in \"1CN5A科技广场\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{(12, 15): [(36, 37, 28)], (12, 14): [(36, 38, 28)]}\n",
    "[{'predicate': '朝代', 'object_type': {'@value': 'Text'}, 'subject_type': '历史人物', 'object': {'@value': '唐'}, 'subject': '王难得', 'h': {'name': '王难得', 'pos': [11, 14]}, 't': {'name': '唐', 'pos': [35, 36]}}, {'predicate': '朝代', 'object_type': {'@value': 'Text'}, 'subject_type': '历史人物', 'object': {'@value': '唐代'}, 'subject': '王难', 'h': {'name': '王难', 'pos': [11, 13]}, 't': {'name': '唐代', 'pos': [35, 37]}}]\n",
    "'宝应二年(763年),王难得死于军中,十三岁的王氏因祖父的战功而入宫为唐代宗才人'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{(2, 12): [(103, 109, 11), (58, 64, 9), (14, 17, 30), (35, 49, 26), (76, 93, 9), (65, 75, 9)], (2, 6): [(35, 39, 26)]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\r\n",
    "text_len = 300\r\n",
    "s2ro_map = {(2, 12): [(103, 109, 11), (58, 64, 9), (14, 17, 30), (35, 49, 26), (76, 93, 9), (65, 75, 9)], (2, 6): [(35, 39, 26)]}\r\n",
    "joints = np.zeros((56,text_len,text_len))\r\n",
    "for sub,tails in s2ro_map.items():\r\n",
    "    subs = np.zeros((text_len,text_len))\r\n",
    "    subs[sub[0]:sub[1],:] = 1\r\n",
    "    tail = np.zeros((56,text_len,text_len))\r\n",
    "    for ro in tails:\r\n",
    "        tail[ro[2],:,ro[0]:ro[1]]=1\r\n",
    "    joints += ((subs+tail)==2).astype(\"int\")\r\n",
    "if len(np.where(joints>=2)[0]):\r\n",
    "    print(s2ro_map)\r\n",
    "joints = (joints>=1).astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{(2, 12): [(58, 93, 9), (103, 109, 11), (35, 49, 26), (14, 17, 30)]}\n"
     ]
    }
   ],
   "source": [
    "def extract_bboxes(mask):\n",
    "    triple_listes = {}\n",
    "    for j in range(mask.shape[0]):\n",
    "        m = mask[j,:,:]\n",
    "        h = np.where(np.any(m,axis = 0))[0]\n",
    "        v = np.where(np.any(m,axis = 1))[0]\n",
    "        if h.shape[0]:\n",
    "            object_head,object_tail = h[[0,-1]]\n",
    "            subject_head,subject_tail = v[[0,-1]]\n",
    "            sub = (subject_head,subject_tail+1)\n",
    "            if sub not in triple_listes:\n",
    "                triple_listes[sub]=[(object_head,object_tail+1,j)]\n",
    "            else:\n",
    "                triple_listes[sub].append((object_head,object_tail+1,j))\n",
    "\n",
    "    return triple_listes\n",
    "print(extract_bboxes(joints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('朱拉美容集团', '2008年')\nFalse -1\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'predicate': '成立日期',\n",
       "  'object_type': {'@value': 'Date'},\n",
       "  'subject_type': '机构',\n",
       "  'object': {'@value': '2008年'},\n",
       "  'subject': '泰国朱拉',\n",
       "  'h': {'name': '泰国朱拉', 'pos': [42, 46]},\n",
       "  't': {'name': '2008年', 'pos': [53, 58]}},\n",
       " {'predicate': '成立日期',\n",
       "  'object_type': {'@value': 'Date'},\n",
       "  'subject_type': '机构',\n",
       "  'object': {'@value': '2008年'},\n",
       "  'subject': '朱拉美容集团',\n",
       "  'h': {'name': '朱拉美容集团', 'pos': [44, 50]},\n",
       "  't': {'name': '2008年', 'pos': [53, 58]}}]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "def judge_(sub_obj,candidate):\n",
    "    same = False\n",
    "    can_sub,can_obj = candidate\n",
    "    sam_index = -1\n",
    "    for i,(sub,obj) in enumerate(sub_obj):\n",
    "        if can_sub.lower() in sub.lower() and can_obj.lower() in obj.lower():\n",
    "            same = True\n",
    "            break\n",
    "        elif sub.lower() in can_sub.lower() and obj.lower() in can_obj.lower():\n",
    "            same = True\n",
    "            sam_index = i\n",
    "            break\n",
    "        elif sub.lower() in can_sub.lower() and can_obj.lower() in obj.lower():\n",
    "            same = True\n",
    "            break\n",
    "        elif can_sub.lower() in sub.lower() and obj.lower() in can_obj.lower():\n",
    "            same = True\n",
    "            break\n",
    "\n",
    "    return same,sam_index\n",
    "\n",
    "def judge_same_sub_obj(spos):\n",
    "    sub_obj = []\n",
    "    new_spos = []\n",
    "    for spo in spos:\n",
    "        sub = spo['subject']\n",
    "        obj = spo['object']['@value']\n",
    "        if len(sub_obj)==0:\n",
    "            sub_obj.append((sub,obj))\n",
    "            new_spos.append(spo)\n",
    "        else:\n",
    "            print((sub,obj))\n",
    "            same,sam_index = judge_(sub_obj,(sub,obj))\n",
    "            print(same,sam_index)\n",
    "            if same:\n",
    "                if sam_index !=-1:\n",
    "                    sub_obj[sam_index] = (sub,obj)\n",
    "                    new_spos[sam_index] = spo\n",
    "            else:\n",
    "                new_spos.append(spo)\n",
    "                sub_obj.append((sub,obj))\n",
    "            \n",
    "    return new_spos\n",
    "\n",
    "def filter_data(spo_lists):\n",
    "    new_spo_lists = []\n",
    "    same_predicate = defaultdict(list)\n",
    "    for spo in spo_lists:\n",
    "        predicate = spo['predicate']\n",
    "        same_predicate[predicate].append(spo)\n",
    "    \n",
    "    for key,values in same_predicate.items():\n",
    "        value = judge_same_sub_obj(values)\n",
    "        new_spo_lists.extend(value)\n",
    "    return new_spo_lists\n",
    "spo_lists = [{'predicate': '成立日期', 'object_type': {'@value': 'Date'}, 'subject_type': '机构', 'object': {'@value': '2008年'}, 'subject': '泰国朱拉', 'h': {'name': '泰国朱拉', 'pos': [42, 46]}, 't': {'name': '2008年', 'pos': [53, 58]}}, {'predicate': '成立日期', 'object_type': {'@value': 'Date'}, 'subject_type': '机构', 'object': {'@value': '2008年'}, 'subject': '朱拉美容集团', 'h': {'name': '朱拉美容集团', 'pos': [44, 50]}, 't': {'name': '2008年', 'pos': [53, 58]}}]\n",
    "filter_data(spo_lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'泰国朱拉美容集团成立于2008年,与国内各大知名网站合作,推出适合女性魅力产品-泰国朱拉,关爱女性健康与美丽,致力于成为高品质的女性服务品牌,主要成分是野葛根,适用乳房偏小、松弛、外扩、平胸、产后下垂、发育不良、减肥减了胸等乳房缺憾问题'"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "text = \"泰国朱拉都没有听说过,亲,你落伍了撒,泰国朱拉是泰国朱拉美容保健集团旗下的系列产品,泰国朱拉美容集团成立于2008年,与国内各大知名网站合作,推出适合女性魅力产品-泰国朱拉,关爱女性健康与美丽,致力于成为高品质的女性服务品牌,主要成分是野葛根,适用乳房偏小、松弛、外扩、平胸、产后下垂、发育不良、减肥减了胸等乳房缺憾问题\"\n",
    "text[42:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "常量 PI 的值近似为：13443555.230。\n"
     ]
    }
   ],
   "source": [
    "print('常量 PI 的值近似为：%5.3f。' % 13443555.23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         ...,\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.rand(10,200)\n",
    "a = a.unsqueeze(-1)\n",
    "b = a.repeat(1,1,10)\n",
    "c = a.expand(-1,-1,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}