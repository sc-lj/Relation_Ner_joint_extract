{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('py36': conda)",
   "metadata": {
    "interpreter": {
     "hash": "0071b0df4086e0dd43ff94b5e10b228431ac274c4976b692451948239530b261"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "files = \"./CasRel/data/baidu/duie_train.json\"\n",
    "with open(files,\"rb\") as f:\n",
    "    data = f.readlines()\n",
    "index = 0\n",
    "a = ['上映时间', '专业代码', '改编自', '修业年限', '成立日期', 'ondate_date', '董事长', '注册资本', '占地面积', '人口数量', '所属专辑', 'inwork_影视作品', '编剧', '歌手', '票房', '导演', '主演', 'period_number', '邮政编码', '作者', '简称', '面积', '作曲', '作词']\n",
    "predicates = set()\n",
    "max_leng = 0\n",
    "for line in data:\n",
    "    line = json.loads(line)\n",
    "    spo_list = line['spo_list']\n",
    "    text = line['text']\n",
    "    max_leng = max(len(text),max_leng)\n",
    "    for spo in spo_list:\n",
    "        s = spo['subject']\n",
    "        p = spo['object']['@value']\n",
    "        predicate = spo['predicate']\n",
    "        if ( s.isdigit() or p.isdigit() ) and predicate == a[1]:\n",
    "            # print(p+\"\\t\"+predicate+\"\\t\"+s+\"\\t\"+text)\n",
    "            predicates.add(predicate)\n",
    "            index += 1\n",
    "# print(predicates)\n",
    "print(max_leng)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "aa = np.array([[0.0349,  0.0670, -0.0612, 0.0280, -0.0222,  0.0422],\n",
    "         [-1.6719,  0.1242, -0.6488, 0.3313, -1.3965, -0.0682],\n",
    "         [-1.3419,  0.4485, -0.6589, 0.1420, -0.3260, -0.4795]])\n",
    "bb = np.array([[-0.0658, -0.1490, -0.1684, 0.7188,  0.3129, -0.1116],\n",
    "         [-0.2098, -0.2980,  0.1126, 0.9666, -0.0178,  0.1222],\n",
    "         [ 0.1179, -0.4622, -0.2112, 1.1151,  0.1846,  0.4283]])\n",
    "cc = np.where(aa>0)     #合并a,b两个tensor，如果a中元素大于0\n",
    "dd = np.where(bb>0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "sub_heads = torch.tensor([2,3,2,5,2,7,6,7,8,2])\n",
    "sub_tails = torch.tensor([5,7,5,2,7,3,8,7,8,7])\n",
    "sub_head_mapping = torch.zeros(10,1,9)\n",
    "sub_tail_mapping = torch.zeros(10,1,9)\n",
    "sub_head_mapping.scatter_(-1,sub_heads.reshape(10,1,1),1)\n",
    "sub_tail_mapping.scatter_(-1,sub_tails.reshape(10,1,1),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "text = \"内地影视演员龚蓓苾携手周渝民、迪丽热巴、张彬彬、刘芮麟、赖艺、代斯、张赫等主创悉数出席\"\n",
    "tokenizer = BertTokenizer.from_pretrained(\"../chinese_bert_base\")\n",
    "# print(tokenizer.tokenize(text))\n",
    "# token = ['龚', '蓓', '苾', '携', '手', '周', '渝', '民', '、', '迪', '丽', '热', '巴', '、', '张', '彬', '彬', '、', '刘', '芮', '麟', '、', '赖', '艺', '、', '代', '斯', '、', '张', '赫', '等', '主', '创', '悉', '数', '出', '席']\n",
    "# tokenizer.convert_tokens_to_ids(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([10, 30, 100])\ntorch.Size([10, 30, 4, 100])\ntorch.Size([10, 30, 4, 50])\ntorch.Size([10, 30, 4, 25])\ntorch.Size([10, 30, 4, 25, 2])\ntorch.Size([10, 30, 4, 50])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "head_size = 50\n",
    "heads=4\n",
    "a = torch.rand(10,30,head_size* heads * 2)\n",
    "input1 = torch.split(a,head_size*2,dim = -1)\n",
    "print(input1[0].shape)\n",
    "input2 = torch.stack(input1, axis=-2)\n",
    "print(input2.shape)\n",
    "qw, kw = input2[..., :head_size], input2[..., head_size:]\n",
    "print(qw.shape)\n",
    "print(qw[..., 1::2].shape)\n",
    "qw2 = torch.stack([-qw[..., 1::2], qw[..., ::2]], 4)\n",
    "print(qw2.shape)\n",
    "qw2 = torch.reshape(qw2, qw.shape)\n",
    "print(qw2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(10, 20, 400)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "inputs = tf.random_normal((10,20,head_size* heads * 2))\n",
    "print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4\n(10, 20, 100)\n(10, 20, 4, 100)\n(10, 20, 4, 50)\n(10, 20, 4, 25, 2)\n(10, 20, 4, 50)\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.split(inputs, heads, axis=-1)\n",
    "print(len(input1))\n",
    "print(input1[0].shape)\n",
    "input2 = K.stack(input1, axis=-2)\n",
    "print(input2.shape)\n",
    "qw, kw = input2[..., :head_size], input2[..., head_size:]\n",
    "print(qw.shape)\n",
    "qw2 = K.stack([-qw[..., 1::2], qw[..., ::2]], 4)\n",
    "print(qw2.shape)\n",
    "qw2 = K.reshape(qw2, K.shape(qw))\n",
    "print(qw2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 100, 25, 2])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.rand((10,100,20))\n",
    "output_dim = 50\n",
    "position_ids = torch.arange(0, 100, dtype=torch.float).reshape(1,-1)\n",
    "indices = torch.arange(0, output_dim // 2, dtype=torch.float)\n",
    "indices = torch.pow(10000.0, -2 * indices / output_dim).reshape(1,-1)\n",
    "embeddings = torch.matmul(position_ids.unsqueeze(-1),indices.unsqueeze(0))\n",
    "embeddings = torch.stack([torch.sin(embeddings), torch.cos(embeddings)], axis=-1)\n",
    "# embeddings = torch.reshape(embeddings, (-1, 100, output_dim))\n",
    "print(embeddings.shape)\n",
    "# embeddings = embeddings.repeat([10, 1, 1])\n",
    "# torch.cat([inputs, embeddings],axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(25,)\n(1, 100, 50)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat:0' shape=(10, 100, 70) dtype=float32>"
      ]
     },
     "metadata": {},
     "execution_count": 76
    }
   ],
   "source": [
    "inputs = tf.random_normal((10,100,20))\n",
    "position_ids = K.arange(0, 100, dtype=K.floatx())[None]\n",
    "\n",
    "indices = K.arange(0, output_dim // 2, dtype=K.floatx())\n",
    "indices = K.pow(10000.0, -2 * indices / output_dim)\n",
    "print(indices.shape)\n",
    "embeddings = tf.einsum('bn,d->bnd', position_ids, indices)\n",
    "embeddings = K.stack([K.sin(embeddings), K.cos(embeddings)], axis=-1)\n",
    "embeddings = K.reshape(embeddings, (-1, 100, output_dim))\n",
    "\n",
    "print(embeddings.shape)\n",
    "embeddings = K.tile(embeddings, [10, 1, 1])\n",
    "K.concatenate([inputs, embeddings])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([10, 2, 30, 20])\ntorch.Size([10, 2, 30, 20])\ntorch.Size([10, 2, 20, 30])\ntorch.Size([10, 2, 20, 30])\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]],\n",
       "\n",
       "\n",
       "        [[[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "         [[True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          ...,\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True],\n",
       "          [True, True, True,  ..., True, True, True]]]])"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "qw = torch.rand(10,30,2,20)\n",
    "kw = torch.rand(10,30,2,20)\n",
    "# torch.matmul(qw.transpose(2,1),kw.permute(0,3,1,2))\n",
    "print(qw.transpose(2,1).shape)\n",
    "kww = kw.transpose(2,1)\n",
    "print(kww.shape)\n",
    "print(kww.transpose(3,2).shape)\n",
    "print(kw.permute(0,2,3,1).shape)\n",
    "kww.transpose(3,2) == kw.permute(0,2,3,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3.1007533\n[0.6931472 1.6931472 2.6931472]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[0., 1., 2.], [0., 1., 2.]])\n",
    "y1 = tf.reduce_logsumexp(x)             # 3.1007533\n",
    "y2 = tf.reduce_logsumexp(x, 0)\n",
    "\n",
    "sess = tf.Session()\n",
    "# Evaluate the tensor `c`.\n",
    "\n",
    "print(sess.run(y1))\n",
    "print(sess.run(y2))\n",
    "x = torch.tensor([[0., 1., 2.], [0., 1., 2.]])\n",
    "y2 = torch.logsumexp(x, dim=0)\n",
    "print(y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "        3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "        4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], dtype=int64),\n",
       " array([0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4,\n",
       "        4, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 8, 8, 8, 8, 9, 9, 9,\n",
       "        9, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n",
       "        3, 3, 3, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7,\n",
       "        7, 8, 8, 8, 9, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2,\n",
       "        2, 2, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
       "        6, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5,\n",
       "        5, 5, 5, 5, 6, 6, 6, 7, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 0, 0, 0, 0,\n",
       "        1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 4, 4, 4, 5, 5, 5, 5, 6, 6,\n",
       "        6, 6, 7, 7, 7, 8, 8, 8, 8, 9, 9], dtype=int64),\n",
       " array([2, 3, 4, 7, 8, 0, 1, 5, 7, 8, 0, 1, 2, 4, 5, 8, 1, 2, 3, 4, 5, 8,\n",
       "        9, 0, 4, 7, 9, 1, 2, 3, 4, 5, 8, 9, 2, 5, 6, 1, 5, 7, 9, 0, 5, 7,\n",
       "        8, 1, 2, 4, 5, 6, 7, 8, 2, 6, 7, 8, 9, 1, 2, 3, 6, 8, 9, 0, 1, 5,\n",
       "        6, 7, 9, 1, 2, 3, 5, 8, 9, 0, 3, 4, 5, 7, 8, 0, 3, 7, 8, 0, 1, 2,\n",
       "        6, 0, 2, 8, 1, 3, 4, 5, 6, 7, 1, 2, 3, 4, 8, 9, 0, 1, 2, 3, 0, 4,\n",
       "        6, 7, 0, 5, 6, 7, 9, 0, 1, 4, 6, 7, 0, 2, 3, 5, 6, 7, 8, 9, 0, 3,\n",
       "        8, 0, 1, 3, 6, 0, 2, 3, 4, 5, 6, 7, 0, 1, 2, 7, 8, 0, 2, 3, 5, 7,\n",
       "        9, 0, 3, 5, 8, 9, 0, 2, 3, 4, 6, 9, 1, 4, 5, 7, 4, 7, 8, 9, 0, 2,\n",
       "        3, 4, 7, 8, 3, 4, 9, 2, 6, 7, 9, 0, 3, 5, 7, 8, 0, 3, 1, 4, 7, 8,\n",
       "        0, 1, 4, 5, 7, 1, 2, 4, 8, 9, 2, 4, 7, 0, 4, 7, 0, 2, 5, 8, 0, 4,\n",
       "        7, 8, 0, 6, 8, 0, 1, 4, 6, 1, 6], dtype=int64))"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.where(np.random.rand(5,10,10)>0.5)"
   ]
  }
 ]
}